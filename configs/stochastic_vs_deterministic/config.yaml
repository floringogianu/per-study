mdp_size: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]

reward_noise_precision: [0, 0.01, 0.1, 0.5, 1]

experience_replay:
  - {"__name": "uniform", "batch_size": 32, "sampling": "uniform"}
  - {"__name": "rank-td", "batch_size": 32, "sampling": "rank", "alpha": 0.95}

  - {"__name": "rank-bayes-β0.001-p0.9",
     "sampling": "rank", "batch_size": 32, "alpha": 0.95,
     "bayesian": yes, "boot_p": 0.9, "boot_no": 21, "boot_beta": 0.001,
     "boot_shuffle": yes}
  - {"__name": "rank-bayes-β0.1-p0.9",
     "sampling": "rank", "batch_size": 32, "alpha": 0.95,
     "bayesian": yes, "boot_p": 0.9, "boot_no": 21, "boot_beta": 0.1,
     "boot_shuffle": yes}
  - {"__name": "rank-bayes-β0.001-p0.5",
     "sampling": "rank", "batch_size": 32, "alpha": 0.95,
     "bayesian": yes, "boot_p": 0.5, "boot_no": 21, "boot_beta": 0.001,
     "boot_shuffle": yes}
  - {"__name": "rank-bayes-β0.1-p0.5",
     "sampling": "rank", "batch_size": 32, "alpha": 0.95,
     "bayesian": yes, "boot_p": 0.5, "boot_no": 21, "boot_beta": 0.1,
     "boot_shuffle": yes}